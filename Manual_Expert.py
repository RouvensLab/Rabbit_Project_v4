import numpy as np
import time
from collections import deque

class ManualExpert:
    def __init__(self, sim_freq= 5):
        self.sim_freq = sim_freq
        self.current_action = [0 for i in range(9)]
        self.action_key = 0

        #define an action handling list
        # sprinting v1
        # self.action_timetable = {
        #     0:  [-0, 0.0,   -0.5, 0.3,  -0.5, 0.3,    0.2, 0.2],
        #     0.2:  [1, 0.2,   -0.2, 0.3,   -0.2, 0.3,    -1, -1],
        #     0.5:  [1, 0.2,   -0.2, -0.4,   -0.2, -0.4,    -1, -1],
        #     0.6:  [-1, 0.2,   -0.4, 0.7,   -0.4, 0.7,    0.2, 0.2],
        #     0.7 :  [-1, 0.0,   -0.5, 0.7,   -0.5, 0.7,    0.2, 0.2],
            
        #     0.7: [-1, 0,   -0.4, 0,   -0.4, 0,    0, 0]
        # }

        #balancesprinting
        #self.action_timetable = {0.0: [-1.0, 0.0, -0.3, 0.3, -0.3, 0.3, 0.7, 0.7], 0.1: [-0.7, 0.0, -0.16, 0.6, -0.16, 0.6, -0.4, -0.4], 0.25: [-0.0, 0.0, 0.2, 0.4, 0.2, 0.4, -0.4, -0.4], 0.35: [0.8, 0.0, -0.1, 0.0, -0.1, 0.0, 0.6, 0.6], 0.5: [-1.0, 0.0, -0.3, 0.5, -0.3, 0.5, 0.65, 0.65], 0.6: [-1.0, 0.0, -0.4, -0.6, -0.4, -0.6, 1.0, 1.0]}
        #self.action_timetable = {0.0: [-0.9, 0.0, -0.3, 0.2, -0.3, 0.2, 0.7, 0.7], 0.05: [-0.9, 0.0, -0.4, 0.6, -0.4, 0.6, -0.4, -0.4], 0.1: [0.7, 0.0, 0.0, 0.0, 0.0, 0.0, -0.4, -0.4], 0.2: [0.7, 0.0, 0.0, -0.5, 0.0, -0.5, 0.7, 0.7], 0.3: [-0.9, 0.0, -0.1, 0.7, -0.1, 0.7, 0.7, 0.7], 0.5: [-1.0, 0.0, -0.4, -0.6, -0.4, -0.6, 1.0, 1.0]}
        # sprinting v2
        # self.action_timetable = {
        #     0:  [0.2, 0,   -0.4, 0.4,  -0.4, 0.4,    0.3, 0.3],
        #     0.2:  [1, 0,   -0., 0.4,   -0., 0.4,    -0.7, -0.7],
        #     0.4:  [1, 0,   -0., -0.6,   -0., -0.6,    -0.7, -0.7],
        #     0.5:  [-0.8, 0,   -0.1, -0.6,   -0.1, -0.6,    -0.7, -0.7],
        #     0.6:  [-0.8, 0,   -0.4, 0.7,   -0.4, 0.7,    0.4, 0.4],
        #     0.7 :  [0.2, 0,   -0.4, 0.4,  -0.4, 0.4,    0.3, 0.3],
            
        #     0.7: [-1, 0,   -0.4, 0,   -0.4, 0,    0, 0]
        # }

        #self.action_timetable = {0.0: [-0.8, 0.0, -0.4, 0.6, -0.4, 0.6, 1.0, 1.0], 0.1: [0.8, 0.0, -0.4, 0.6, -0.4, 0.6, -0.7, -0.7], 0.2: [0.8, 0.0, 0.0, 0.3, 0.0, 0.3, -0.7, -0.7], 0.3: [-0.8, 0.0, -0.4, 0.6, -0.4, 0.6, 1.0, 1.0], 0.5: [-1.0, 0.0, -0.4, -0.6, -0.4, -0.6, -0.7, 0.8]}
        
        #other best reallive Expert
        #self.action_timetable = {0.0: [-0.8, 0.0, -0.0, 0.3, -0.0, 0.3, -1.0, -1.0], 0.2: [-0.3, 0.0, 0.25, 0.3, 0.25, 0.3, -1.0, -1.0], 0.3: [0.2, 0.0, 0.4, -0.6, 0.4, -0.6, 0.4, 0.4], 0.4: [-0.2, 0.0, -0.1, 0.5, -0.1, 0.5, 0.5, 0.5], 0.45: [-0.5, 0.0, -0.1, 0.5, -0.1, 0.5, 0.5, 0.5], 0.6: [-0.5, 0.0, -0.1, 0.3, -0.1, 0.3, 0.5, 0.5], 0.8: [-1.0, 0.0, -0.4, -0.6, -0.4, -0.6, 1.0, 1.0]}
        
        #pusch sprint v1
        #self.action_timetable = {0.0: [-0.5, 0.0, -0.2, 0.4, -0.2, 0.4, -0.5, -0.5], 0.2: [-0.5, 0.0, 0.5, -0.4, 0.5, -0.4, 1.0, 1.0], 0.45: [1.0, 0.0, 0.5, 0.6, 0.5, 0.6, 0.0, 0.0], 0.6: [1.0, 0.0, -0.2, 0.6, -0.2, 0.6, -0.5, -0.5], 0.7: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}

        #big jumps
        #self.action_timetable = {0.0: [0.5, 0.0, -0.2, -0.3, -0.2, -0.3, 0.0, 0.0], 0.25: [0.4, 0.0, -0.2, 0.2, -0.2, 0.2, 0.0, 0.0], 0.5: [0.1, 0.0, -0.8, -0.9, -0.8, -0.9, -0.5, -0.5], 0.75: [1.0, 0.0, 0.1, 0.5, 0.1, 0.5, 0.0, 0.0]}
        #fast jump Sim
        #self.action_timetable = {0.0: [0.9, 0.0, -0.3, 0.4, -0.3, 0.4, 0.0, 0.0], 0.25: [0.7, 0.0, -0.5, 0.3, -0.5, 0.3, 0.0, 0.0], 0.3: [0.1, 0.0, -0.6, 0.0, -0.6, 0.0, -0.5, -0.5], 0.8: [1.0, 0.0, 0.3, 0.4, 0.3, 0.4, -0.5, -0.5]}
        #Sim Jumps
        #self.action_timetable = {0.0: [0.8, 0.0, -0.4, 0.2, -0.4, 0.2, 0.0, 0.0], 0.2: [0.1, 0.0, -0.4, 0.5, -0.4, 0.5, -0.7, -0.7], 0.35: [0.1, 0.0, -0.5, -0.2, -0.5, -0.2, -0.7, -0.7], 0.657: [1.0, 0.0, -0.1, 0.5, -0.1, 0.5, 0.0, 0.0]}
        #slow jumps
        #self.action_timetable = {0.0: [1.0, 0.0, 0.3, 0.4, 0.3, 0.4, 0.0, 0.0], 1.0: [0.5, 0.0, -0.3, 0.4, -0.3, 0.4, -0.5, -0.5], 1.25: [0.1, 0.0, -0.5, 0.3, -0.5, 0.3, -0.5, -0.5], 1.3: [0.1, 0.0, -0.6, 0.0, -0.6, 0.0, -0.5, -0.5], 1.8: [1.0, 0.0, 0.3, 0.4, 0.3, 0.4, -0.5, -0.5]}
        self.action_timetable =  {0.0: [0.9, 0.0, 0.0, 0.4, 0.0, 0.4, -0.8, -0.8], 0.4: [0.7, 0.0, -0.4, 0.0, -0.4, 0.0, -0.8, -0.8], 0.6: [0.1, 0.0, -0.5, 0.3, -0.5, 0.3, 0.0, 0.0], 1.3: [1.0, 0.0, 0.2, 0.6, 0.2, 0.6, 0.0, 0.0]}                   
        #MÃ¤nnchen
        #self.action_timetable = {0.0: [-0.003936767578125, 0.00390625, 0.00390625, -0.003936767578125, 0.00390625, -0.003936767578125, -1.0, -1.0], 1.0: [-0.003936767578125, 0.00390625, 0.00390625, -0.003936767578125, 0.00390625, -0.003936767578125, -1.0, -1.0], 2.0: [0.999969482421875, 0.00390625, 0.00390625, 0.999969482421875, 0.00390625, 0.999969482421875, -1.0, -1.0], 3.0: [0.999969482421875, 0.00390625, -0.129425048828125, 0.403900146484375, -0.129425048828125, 0.403900146484375, -1.0, -1.0], 4.0: [0.999969482421875, 0.00390625, -0.62353515625, 0.529388427734375, -0.62353515625, 0.529388427734375, -1.0, -1.0], 5.0: [0.999969482421875, 0.00390625, 0.00390625, 0.450958251953125, 0.00390625, 0.450958251953125, -1.0, -1.0], 6.0: [-0.835296630859375, -0.4039306640625, 0.00390625, 0.01959228515625, 0.00390625, 0.01959228515625, -0.13726806640625, -0.160797119140625], 7.0: [-0.207855224609375, -1.0, 0.00390625, -0.003936767578125, 0.00390625, -0.003936767578125, -0.23138427734375, -0.254913330078125], 8.0: [-0.003936767578125, 0.00390625, 0.00390625, -0.003936767578125, 0.00390625, -0.003936767578125, 0.137237548828125, -0.04315185546875], 9.0: [0.192138671875, 0.999969482421875, 0.00390625, -0.003936767578125, 0.00390625, -0.003936767578125, 0.1607666015625, -0.207855224609375]}
        
        #slow jumps
        #self.action_timetable = {0.0: [-0.003936767578125, 0.0, -0.003936767578125, 0.0, -0.003936767578125, 0.0, -0.160797119140625, -0.160797119140625], 1.0: [0.999969482421875, 0.0, 0.00390625, 0.2, 0.00390625, 0.2, -0.160797119140625, -0.160797119140625], 2.0: [0.5, 0.0, -0.4039306640625, 0.3, -0.4039306640625, 0.3, -1.0, -1.0], 3.0: [0.5, 0.0, -0.5, 0.5, -0.5, 0.5, -0.160797119140625, -0.0902099609375]}

    
    
    def think_and_respond(self, obs_, state, done, current_time=0):
        # Define the action based on the time table
        action_keytimes = list(self.action_timetable.keys())
        #get the action which is at the current time step
        last_time = action_keytimes[-1]
        
        #find the next action key
        if (0 ==last_time):
            time_in_timetable = 0
        else:
            time_in_timetable = current_time % last_time
        #search nearest key
        action_key = min(action_keytimes, key=lambda x:abs(x-time_in_timetable))

        action = self.action_timetable[action_key]
        state = obs_[:-1]
        action_index = list(self.action_timetable.keys()).index(action_key)
        #print(action_index)
        return np.array(action), state, action_index
    

